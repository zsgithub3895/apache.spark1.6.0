package com.sihuatech.sqm.spark.kafkaTwo;

public class SparkHive {
	/*JavaHiveContext hiveContext = new JavaHiveContext();
	public static void main(String[] args) {
		JavaSchemaRDD result = hiveContext.hql("select count(*), host, module " +
		                "from ewaplog " +
		                "group by host, module " +
		                "order by host, module");
		List<Row> collect = result.collect();
		for (Row row : collect) {
		    System.out.println(row.get(0) + "\t" + row.get(1) + "\t" + row.get(2));
		}

	}*/

}
